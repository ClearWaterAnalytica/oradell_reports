---
title: "Predicting"
layout: about
image: /assets/images/HAB_2.jpg
---

A brief description of our methods. Create link to whitepaper (and ultimately the peer reviewed publication)

Issue -- big data; don't know what to do with it
The historical data collected from Detroit Lake includes measurements of temperature, humidity, wind speed, nutrient levels, algal and toxin concentrations. Now the question is... what can be done with these data? Methods from applied mathematics and computer science, for example Machine Learning, have been used for predicting harmful algal blooms in other lakes (here in the US, and around the world). Our goal is to use these cutting edge methods to predict harmful algal blooms in Detroit Lake, and also advance the state-of-the-art and develop new forward-looking algorithms to give us the best possible predictions.

Importantly, the City of Salem asked for three important products:

1) 

hallenge -- big data is spotty and the lake is complex

Key wants: 1) predictions, 2) uncertainty, 3) informed sampling (identify key locations and variables)

Solution -- Machine Learning, what is it and how does it work

Specifically -- Bayesian Model Averaging + 1) BNNs (new and shiny) and 2) (non)linear models (i.e. state of the art...)




